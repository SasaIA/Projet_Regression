{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping\n",
    "\n",
    "On doit scrappé : \n",
    "- Titre d'emploi, \n",
    "- Le nom de la société, \n",
    "- La localisation, \n",
    "- Type de contrat, \n",
    "- Salaire,\n",
    "- Détail du job,\n",
    "- Temps de travail, \n",
    "- Les critères du candidat: niveau d'études minimum requis, la formation, niveau d'expérience minimum, les langues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install chromedriver_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromedriver_binary\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more data!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-9dce138844b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m \u001b[0mscrapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"Datascientist\"'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'France'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-9dce138844b0>\u001b[0m in \u001b[0;36mscrapping\u001b[1;34m(job, where)\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mmo1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatchSalary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescJob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                     \u001b[0mgetInfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Salary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmo1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mNoSuchElementException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[0mgetInfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Salary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No Info'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "def scrapping(job, where):\n",
    "    browser = webdriver.Chrome(executable_path=\"C:/Users/Utilisateur/Desktop/Selenium/chromedriver/chromedriver.exe\")\n",
    "    \n",
    "    browser.get('https://www.indeed.fr/')\n",
    "    browser.maximize_window()\n",
    "    \n",
    "    #Search name Job\n",
    "    searchInput = browser.find_element_by_class_name('icl-TextInput-control')\n",
    "    searchInput.send_keys(job)\n",
    "    #Search Where\n",
    "    searchInput = browser.find_element_by_id('text-input-where')\n",
    "    searchInput.send_keys(where)\n",
    "    #Click search\n",
    "    clickSearch = browser.find_element_by_class_name('icl-Button')\n",
    "    clickSearch.click()\n",
    "    \n",
    "    #Dict\n",
    "    getInfo = {'Job Title': [], 'Name Company': [], 'Location': [], 'Type of contract': [], 'Salary': [], 'Minimum level of education required': [], 'Minimum experience level required': [], 'Spoken languages': []}\n",
    "    nameJob = browser.find_elements_by_class_name('jobsearch-SerpJobCard')\n",
    "        \n",
    "    #Scrapping    \n",
    "    while True:\n",
    "        #Fermer un popup\n",
    "        try:\n",
    "            time.sleep(0.5)\n",
    "            browser.find_element_by_class_name('popover-x-button-close').click()    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #Ouvrir job\n",
    "        for i in nameJob:\n",
    "            i.click()\n",
    "            time.sleep(2)\n",
    "            \n",
    "            try:\n",
    "                try:\n",
    "                    getInfo['Job Title'].append(i.find_element_by_class_name('title').text)\n",
    "                except NoSuchElementException:\n",
    "                    getInfo['Job Title'].append('No Info')\n",
    "\n",
    "                try:\n",
    "                    getInfo['Name Company'].append(i.find_element_by_class_name('company').text)\n",
    "                except NoSuchElementException:\n",
    "                    getInfo['Name Company'].append('No Info')\n",
    "\n",
    "                try:\n",
    "                    getInfo['Location'].append(i.find_element_by_class_name('location').text)\n",
    "                except NoSuchElementException:\n",
    "                    getInfo['Location'].append('No Info')\n",
    "                \n",
    "#                 try:\n",
    "#                     getWorkTime = re.match('(\\btemps plein\\b)|(\\btemps partiel\\b)', descJob)\n",
    "#                     getInfo['Work time'].append(getWorkTime)\n",
    "#                 except NoSuchElementException:\n",
    "#                     getInfo['Work time'].append('No Info')\n",
    "    \n",
    "                descJob = browser.find_element_by_xpath(\"//*[@id='vjs-tab-job']/div[1]/div[2]/span[2]\").text\n",
    "                matchContract = re.compile(r'\\bCDI\\b|\\bCDD\\b|\\bAlternance\\b|\\bStage\\b|\\bSTAGE\\b')\n",
    "                mo = matchContract.search(descJob)\n",
    "                try:\n",
    "                    getInfo['Type of contract'].append(mo.group())\n",
    "                except NoSuchElementException:\n",
    "                    getInfo['Type of contract'].append('No Info')\n",
    "                \n",
    "                matchSalary = re.compile(\"r([0-9])\\S+\")\n",
    "                mo1 = matchSalary.search(descJob)\n",
    "                try:\n",
    "                    getInfo['Salary'].append(mo1.group())\n",
    "                except NoSuchElementException:\n",
    "                    getInfo['Salary'].append('No Info')\n",
    "\n",
    "                matchEduLevel = re.compile(\"r(\\bformation supérieure\\b|\\bBAC\\+5\\b|\\bBac\\+5\\b|\\bbac\\+5\\b|\\bBac \\+ 5\\b|\\bDiplôme ingénieur\\b|\\bdiplôme ingénieur\\b|\\bBAC\\+4\\b|\\bBac\\+4\\b|\\bbac\\+4\\b|\\bBac \\+ 4\\b|\\bMaster 2\\b|\\bmaster 2\\b|\\bBAC\\+3\\b|\\bBac\\+3\\b|\\bbac\\+3\\b|\\bBac \\+ 3\\b|\\bgrande école d\\'ingénieur\\b|\\bgrande école d\\’ingénieur\\b|\\bBAC\\+4\\/5\\b|\\bBac\\+4\\/5\\b|\\bbac\\+4\\/5\\b|\\bM2\\b|\\bCursus ingénieur\\b|\\bcursus ingénieur\\b|\\bformation Data Science ou IA\\b|\\bFormation Data Science ou IA\\b|\\bformation Data Science\\b|\\bFormation Data Science\\b|\\buniversité\\b|\\buniversitaire\\b)\")\n",
    "                mo2 = matchEduLevel.search(descJob)\n",
    "                try:\n",
    "                    getInfo['Minimum level of education required'].append(mo2.group())\n",
    "                except NoSuchElementException:\n",
    "                    getInfo['Minimum level of education required'].append('No Info')\n",
    "\n",
    "                \n",
    "                matchExpLevel = re.compile(\"(\\b0 - 2 an\\b|\\b1 an\\b|\\b1 ou 2 ans\\b|\\b2 ans\\b|\\b2\\/3 ans\\b|\\b3 - 5 ans\\b|\\b3 ans\\b|\\b4 ans\\b|\\b5 ans\\b)\")\n",
    "                mo3 = matchExpLevel.search(descJob)\n",
    "                try:\n",
    "                    getInfo['Minimum experience level required'].append(mo3.group())\n",
    "                except NoSuchElementException:\n",
    "                    getInfo['Minimum experience level required'].append('No Info')\n",
    "\n",
    "                matchSpokenLang = re.compile(r\"(\\bAnglais\\b|\\bChinois\\b|\\bArabe\\b|\\bEspagnol\\b|\\bItalien\\b)\")\n",
    "                mo4 = matchSpokenLang.search(descJob)\n",
    "                try:\n",
    "                    getInfo['Spoken languages'].append(mo4.group())\n",
    "                except NoSuchElementException:\n",
    "                    getInfo['Spoken languages'].append('No Info')\n",
    "                \n",
    "            except NoSuchElementException:\n",
    "                print('No more data!')\n",
    "            \n",
    "            browser.find_element_by_class_name('icl-CloseButton')\n",
    "            \n",
    "#         try:\n",
    "#             nextPage = browser.find_element_by_css_selector('[aria-label=\"Suivant\"]')\n",
    "#             nextPage.click()\n",
    "#             time.sleep(3)\n",
    "#         except NoSuchElementException:\n",
    "#             print(\"No more pages\")\n",
    "        \n",
    "#         break\n",
    "        \n",
    "        browser.quit()\n",
    "    \n",
    "        df = pd.DataFrame.from_dict(getInfo, orient='index')\n",
    "        df.to_csv('test.csv', index=False, encoding='utf-8')\n",
    "        return df\n",
    "        \n",
    "scrapping('\"Datascientist\"', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
